"""
Model Paper Generator - Separated by Question Type
Generates O/L Mathematics questions with proper structure
"""

import json
import os
import time
import random
import re
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass, field
from enum import Enum

import google.generativeai as genai


class QuestionType(Enum):
    SHORT_ANSWER = "short_answer"
    STRUCTURED = "structured"
    ESSAY_TYPE = "essay_type"


@dataclass
class GenerationConfig:
    """Configuration for question generation"""
    count: int = 5
    api_delay: float = 4.0
    batch_size: int = 5


class ModelPaperGenerator:
    """
    Generator for O/L Mathematics model paper questions.
    Separate methods for each question type with specialized prompts.
    """
    
    def __init__(self, api_key: str):
        """Initialize the generator"""
        if not api_key:
            raise ValueError("GEMINI_API_KEY is required")
        
        self.api_key = api_key
        genai.configure(api_key=api_key)
        
        self.model_name = "gemini-2.5-flash"
        self.model = None
        
        self.last_request_time = 0
        self.min_request_interval = 2
        
        self.generation_config = {
            'temperature': 0.8,
            'top_p': 0.95,
            'top_k': 40,
            'max_output_tokens': 8192,
        }
        
        self.safety_settings = [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
        ]
        
        # Past paper data
        self.past_paper_questions: List[Dict] = []
        self.past_paper_by_topic: Dict[str, List[Dict]] = {}
        self.past_paper_by_type: Dict[str, List[Dict]] = {}
        self.available_topics: List[str] = []
        self.past_papers_loaded = False
        
        print("‚úÖ Model Paper Generator initialized")
    
    def _ensure_model(self):
        """Lazy load the Gemini model"""
        if self.model is None:
            print(f"Loading model: {self.model_name}")
            self.model = genai.GenerativeModel(self.model_name)
    
    def _rate_limit_wait(self):
        """Implement rate limiting"""
        elapsed = time.time() - self.last_request_time
        if elapsed < self.min_request_interval:
            wait_time = self.min_request_interval - elapsed
            time.sleep(wait_time)
        self.last_request_time = time.time()
    
    def _parse_topics(self, topic_string: str) -> List[str]:
        """Parse topic string - handles combined topics with '/'"""
        if not topic_string:
            return []
        topics = [t.strip() for t in topic_string.split('/')]
        return [t for t in topics if t]
    
    # ==================== Data Loading ====================
    
    def load_past_paper_questions(self, json_path: str) -> bool:
        """Load past paper questions from JSON file."""
        print(f"\n{'='*60}")
        print("üìö LOADING PAST PAPER QUESTIONS")
        print(f"{'='*60}")
        
        # Try multiple paths
        possible_paths = [
            json_path,
            os.path.join(os.path.dirname(__file__), '..', '..', json_path),
            os.path.join(os.path.dirname(__file__), '..', '..', 'data', 'extracted_text', 'model_paper_questions.json'),
            os.path.abspath(json_path),
        ]
        
        actual_path = None
        for path in possible_paths:
            normalized_path = os.path.normpath(path)
            if os.path.exists(normalized_path):
                actual_path = normalized_path
                print(f"‚úÖ Found file at: {actual_path}")
                break
        
        if actual_path is None:
            print(f"‚ùå File not found")
            self.past_papers_loaded = False
            return False
        
        try:
            with open(actual_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            questions = data.get('questions', [])
            
            if not questions:
                print("‚ùå No questions found in the file")
                self.past_papers_loaded = False
                return False
            
            self.past_paper_questions = []
            self.past_paper_by_topic = {}
            self.past_paper_by_type = {}
            all_topics = set()
            
            for q in questions:
                self.past_paper_questions.append(q)
                
                topic_str = q.get('topic', '')
                topics = self._parse_topics(topic_str)
                
                for topic in topics:
                    all_topics.add(topic)
                    if topic not in self.past_paper_by_topic:
                        self.past_paper_by_topic[topic] = []
                    self.past_paper_by_topic[topic].append(q)
                
                q_type = q.get('type', 'short_answer')
                if q_type not in self.past_paper_by_type:
                    self.past_paper_by_type[q_type] = []
                self.past_paper_by_type[q_type].append(q)
            
            self.available_topics = list(all_topics)
            self.past_papers_loaded = True
            
            print(f"üìä Loaded {len(self.past_paper_questions)} questions")
            print(f"üìö Topics: {len(self.available_topics)}")
            print(f"üìù Types: {list(self.past_paper_by_type.keys())}")
            
            return True
            
        except Exception as e:
            print(f"‚ùå Error loading past papers: {e}")
            self.past_papers_loaded = False
            return False
    
    def get_statistics(self) -> Dict:
        """Get statistics about loaded data."""
        return {
            "past_papers_loaded": self.past_papers_loaded,
            "total_questions": len(self.past_paper_questions),
            "available_topics": self.available_topics,
            "questions_by_type": {k: len(v) for k, v in self.past_paper_by_type.items()},
            "questions_by_topic": {k: len(v) for k, v in self.past_paper_by_topic.items()}
        }
    
    def _get_reference_questions(self, topics: List[str], question_type: str, count: int = 2) -> List[Dict]:
        """Get reference questions from past papers."""
        candidates = []
        
        for topic in topics:
            topic_questions = self.past_paper_by_topic.get(topic, [])
            for q in topic_questions:
                if q.get('type') == question_type and q not in candidates:
                    candidates.append(q)
        
        if len(candidates) < count:
            type_questions = self.past_paper_by_type.get(question_type, [])
            for q in type_questions:
                if q not in candidates:
                    candidates.append(q)
                if len(candidates) >= count * 2:
                    break
        
        return random.sample(candidates, min(count, len(candidates))) if candidates else []
    
    def _select_topics(self, count: int) -> List[str]:
        """Select random topics for questions."""
        if not self.available_topics:
            return ["‡∂ú‡∂´‡∑í‡∂≠‡∂∫"] * count
        
        topics = []
        available = self.available_topics.copy()
        random.shuffle(available)
        
        for i in range(count):
            if not available:
                available = self.available_topics.copy()
                random.shuffle(available)
            topics.append(available.pop(0))
        
        return topics
    
    # ==================== SHORT ANSWER GENERATION ====================
    
    def _build_short_answer_prompt(self, topics: List[str], count: int, references: List[Dict]) -> str:
        """Build prompt for short answer questions."""
        
        # Format reference examples
        ref_text = ""
        if references:
            ref_text = "\n=== ‡∂Ü‡∂Ø‡∂ª‡∑ä‡∑Å ‡∂ã‡∂Ø‡∑è‡∑Ñ‡∂ª‡∂´ ===\n"
            for i, ref in enumerate(references[:2], 1):
                ref_text += f"\n‡∂ã‡∂Ø‡∑è‡∑Ñ‡∂ª‡∂´ {i}:\n"
                ref_text += f"‡∂∏‡∑è‡∂≠‡∑ò‡∂ö‡∑è‡∑Ä: {ref.get('topic', '')}\n"
                ref_text += f"‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∂∫: {ref.get('question', '')}\n"
                
                final_ans = ref.get('final_answer', [])
                if final_ans:
                    ref_text += "‡∂¥‡∑í‡∑Ö‡∑í‡∂≠‡∑î‡∂ª‡∑î ‡∂¥‡∑í‡∂∫‡∑Ä‡∂ª:\n"
                    for step in final_ans[:4]:
                        if isinstance(step, dict):
                            desc = step.get('step', '') or ''
                            val = step.get('answer', '')
                            if val:
                                ref_text += f"  ‚Ä¢ {desc} = {val}\n"
        
        topics_str = ", ".join(topics[:5])
        
        prompt = f"""‡∂î‡∂∂ O/L ‡∂ú‡∂´‡∑í‡∂≠‡∂∫ ‡∑Ä‡∑í‡∂∑‡∑è‡∂ú ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂± ‡∑É‡∑è‡∂Ø‡∂± ‡∑Ä‡∑í‡∑Å‡∑ö‡∑Ç‡∂• ‡∂ú‡∑î‡∂ª‡∑î‡∑Ä‡∂ª‡∂∫‡∑ô‡∂ö‡∑ä.

‡∂ö‡∑è‡∂ª‡∑ä‡∂∫‡∂∫: ‡∂ö‡∑ô‡∂ß‡∑í ‡∂¥‡∑í‡∑Ö‡∑í‡∂≠‡∑î‡∂ª‡∑î ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂± {count}‡∂ö‡∑ä ‡∑É‡∑è‡∂Ø‡∂±‡∑ä‡∂±
‡∂∏‡∑è‡∂≠‡∑ò‡∂ö‡∑è: {topics_str}

{ref_text}

=== ‡∂±‡∑í‡∂∏‡∑ê‡∑Ä‡∑î‡∂∏‡∑ä ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í‡∂∫ ===

‡∑É‡∑ë‡∂∏ ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∂∫‡∂ö‡∑ä ‡∑É‡∂≥‡∑Ñ‡∑è ‡∂∏‡∑ô‡∂∏ ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í‡∂∫ ‡∑Ñ‡∂ª‡∑í‡∂∫‡∂ß‡∂∏ ‡∂Ö‡∂±‡∑î‡∂ú‡∂∏‡∂±‡∂∫ ‡∂ö‡∂ª‡∂±‡∑ä‡∂±:

QUESTION_START
NUMBER: [‡∂Ö‡∂Ç‡∂ö‡∂∫]
TOPIC: [‡∂∏‡∑è‡∂≠‡∑ò‡∂ö‡∑è‡∑Ä]
QUESTION: [‡∑É‡∂∏‡∑ä‡∂¥‡∑ñ‡∂ª‡∑ä‡∂´ ‡∂ú‡∂´‡∑í‡∂≠ ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∂∫ ‡∑É‡∑í‡∂Ç‡∑Ñ‡∂Ω‡∑ô‡∂±‡∑ä]
STEPS:
- [‡∂¥‡∑í‡∂∫‡∑Ä‡∂ª 1 ‡∑Ä‡∑í‡∑É‡∑ä‡∂≠‡∂ª‡∂∫] = [‡∂ú‡∂´‡∂±‡∂∫/‡∂¥‡∑í‡∑Ö‡∑í‡∂≠‡∑î‡∂ª]
- [‡∂¥‡∑í‡∂∫‡∑Ä‡∂ª 2 ‡∑Ä‡∑í‡∑É‡∑ä‡∂≠‡∂ª‡∂∫] = [‡∂ú‡∂´‡∂±‡∂∫/‡∂¥‡∑í‡∑Ö‡∑í‡∂≠‡∑î‡∂ª]
- [‡∂¥‡∑í‡∂∫‡∑Ä‡∂ª 3 ‡∑Ä‡∑í‡∑É‡∑ä‡∂≠‡∂ª‡∂∫] = [‡∂ú‡∂´‡∂±‡∂∫/‡∂¥‡∑í‡∑Ö‡∑í‡∂≠‡∑î‡∂ª]
FINAL_ANSWER: [‡∂Ö‡∑Ä‡∑É‡∑è‡∂± ‡∂¥‡∑í‡∑Ö‡∑í‡∂≠‡∑î‡∂ª]
QUESTION_END

---

=== ‡∂±‡∑ì‡∂≠‡∑í ===
1. ‡∑É‡∑ë‡∂∏ ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∂∫‡∂ö‡∂∏ STEPS ‡∂Ö‡∑Ä‡∂∏ ‡∑Ä‡∑Å‡∂∫‡∑ô‡∂±‡∑ä 2-4‡∂ö‡∑ä ‡∂≠‡∑í‡∂∂‡∑í‡∂∫ ‡∂∫‡∑î‡∂≠‡∑î‡∂∫
2. "‡∂ª‡∑î." ‡∂∏‡∑î‡∂Ø‡∂Ω‡∑ä ‡∑É‡∂≥‡∑Ñ‡∑è ‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è ‡∂ö‡∂ª‡∂±‡∑ä‡∂±
3. ‡∂ú‡∂´‡∑í‡∂≠ ‡∑É‡∂Ç‡∂ö‡∑ö‡∂≠: ¬≤, ¬≥, œÄ, ‚àö, √ó, √∑
4. ‡∑É‡∑ë‡∂∏ ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∂∫‡∂ö‡∂ß‡∂∏ ‡∑Ä‡∑ô‡∂±‡∑É‡∑ä ‡∑É‡∂Ç‡∂õ‡∑ä‚Äç‡∂∫‡∑è ‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è ‡∂ö‡∂ª‡∂±‡∑ä‡∂±
5. ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂± --- ‡∂∏‡∂ú‡∑í‡∂±‡∑ä ‡∑Ä‡∑ô‡∂±‡∑ä ‡∂ö‡∂ª‡∂±‡∑ä‡∂±

=== ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂± ‡∑Ä‡∂ª‡∑ä‡∂ú ‡∂ã‡∂Ø‡∑è‡∑Ñ‡∂ª‡∂´ ===
- ‡∑É‡∑î‡∑Ö‡∑î ‡∂ö‡∂ª‡∂±‡∑ä‡∂±: (2/3x) + (5/6x) - (7/12x)
- ‡∑É‡∑è‡∂∞‡∂ö ‡∑É‡∑ú‡∂∫‡∂±‡∑ä‡∂±: 2x¬≤ - 18
- ‡∑É‡∂∏‡∑ì‡∂ö‡∂ª‡∂´‡∂∫ ‡∑Ä‡∑í‡∑É‡∂≥‡∂±‡∑ä‡∂±: 3x + 5 = 20
- ‡∂¥‡∑ú‡∂Ω‡∑í‡∂∫ ‡∂ú‡∂´‡∂±‡∂∫ ‡∂ö‡∂ª‡∂±‡∑ä‡∂±: ‡∂ª‡∑î. 50000 ‡∂ö‡∑ä 8% ‡∂¥‡∑ú‡∂Ω‡∑í‡∂∫‡∂ß ‡∑Ä‡∑É‡∂ª 2‡∂ö‡∑ä
- ‡∑É‡∂∏‡∑ä‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è‡∑Ä ‡∑É‡∑ú‡∂∫‡∂±‡∑ä‡∂±: ‡∂Ø‡∑è‡∂Ø‡∑î ‡∂ö‡∑ê‡∂ß‡∂∫‡∂ö‡∑ä ‡∂Ø‡∑ô‡∑Ä‡∂ª‡∂ö‡∑ä ‡∂Ø‡∑ê‡∂∏‡∑ñ ‡∑Ä‡∑í‡∂ß...

‡∂Ø‡∑ê‡∂±‡∑ä ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂± {count}‡∂ö‡∑ä ‡∑É‡∑è‡∂Ø‡∂±‡∑ä‡∂±:
"""
        return prompt
    
    def _parse_short_answer_response(self, text: str) -> List[Dict]:
        """Parse short answer questions from response."""
        questions = []
        
        # Split by QUESTION_START...QUESTION_END or ---
        pattern = r'QUESTION_START(.*?)QUESTION_END'
        matches = re.findall(pattern, text, re.DOTALL)
        
        if not matches:
            # Try splitting by ---
            parts = text.split('---')
            for part in parts:
                if 'QUESTION:' in part or 'NUMBER:' in part:
                    matches.append(part)
        
        for match in matches:
            try:
                q_data = {}
                
                # Extract number
                num_match = re.search(r'NUMBER:\s*(\d+)', match)
                q_data['question_number'] = int(num_match.group(1)) if num_match else len(questions) + 1
                
                # Extract topic
                topic_match = re.search(r'TOPIC:\s*(.+?)(?:\n|$)', match)
                q_data['topics'] = [topic_match.group(1).strip()] if topic_match else []
                
                # Extract question
                q_match = re.search(r'QUESTION:\s*(.+?)(?=\nSTEPS:|$)', match, re.DOTALL)
                q_data['question'] = q_match.group(1).strip() if q_match else ""
                
                # Extract steps
                steps = []
                steps_match = re.search(r'STEPS:(.*?)(?=FINAL_ANSWER:|$)', match, re.DOTALL)
                if steps_match:
                    step_lines = steps_match.group(1).strip().split('\n')
                    for line in step_lines:
                        line = line.strip().lstrip('-').strip()
                        if '=' in line:
                            parts = line.split('=', 1)
                            steps.append({
                                "description": parts[0].strip(),
                                "value": parts[1].strip()
                            })
                        elif line:
                            steps.append({
                                "description": line,
                                "value": ""
                            })
                q_data['answer_steps'] = steps
                
                # Extract final answer
                final_match = re.search(r'FINAL_ANSWER:\s*(.+?)(?:\n|$)', match)
                q_data['final_answer'] = final_match.group(1).strip() if final_match else ""
                
                if q_data['question'] and len(q_data['question']) > 10:
                    questions.append(q_data)
                    
            except Exception as e:
                print(f"  ‚ö†Ô∏è Parse error: {e}")
                continue
        
        return questions
    
    def generate_short_answer_questions(
        self,
        count: int = 5,
        topics: Optional[List[str]] = None,
        api_delay: float = 4.0
    ) -> Dict:
        """
        Generate short answer questions.
        
        Args:
            count: Number of questions to generate (1-10)
            topics: Optional list of topics to use
            api_delay: Delay between API calls
        
        Returns:
            Dict with questions and metadata
        """
        print(f"\n{'='*60}")
        print(f"üìù GENERATING {count} SHORT ANSWER QUESTIONS")
        print(f"{'='*60}")
        
        if not self.past_papers_loaded:
            raise ValueError("Past papers not loaded. Call load_past_paper_questions() first.")
        
        self._ensure_model()
        start_time = time.time()
        
        # Select topics if not provided
        if not topics:
            topics = self._select_topics(count)
        
        print(f"üìö Topics: {topics[:5]}...")
        
        # Get reference questions
        references = self._get_reference_questions(topics, 'short_answer', count=2)
        
        all_questions = []
        batch_size = min(5, count)
        attempts = 0
        max_attempts = 3
        
        while len(all_questions) < count and attempts < max_attempts:
            attempts += 1
            remaining = count - len(all_questions)
            batch_count = min(batch_size, remaining + 2)
            
            print(f"\n  Attempt {attempts}: Generating {batch_count} questions...")
            
            self._rate_limit_wait()
            
            try:
                prompt = self._build_short_answer_prompt(topics, batch_count, references)
                
                response = self.model.generate_content(
                    prompt,
                    generation_config=self.generation_config,
                    safety_settings=self.safety_settings
                )
                
                if response.text:
                    new_questions = self._parse_short_answer_response(response.text)
                    
                    for q in new_questions:
                        if len(all_questions) < count:
                            q['question_number'] = len(all_questions) + 1
                            all_questions.append(q)
                    
                    print(f"  ‚úÖ Parsed {len(new_questions)} questions. Total: {len(all_questions)}/{count}")
                
            except Exception as e:
                print(f"  ‚ùå Error: {str(e)[:100]}")
                time.sleep(api_delay)
        
        generation_time = round(time.time() - start_time, 2)
        
        return {
            "type": "short_answer",
            "questions": all_questions,
            "count": len(all_questions),
            "requested": count,
            "topics_used": list(set(topics)),
            "generation_time_seconds": generation_time
        }
    
    # ==================== STRUCTURED QUESTION GENERATION ====================
    
    def _build_structured_prompt(self, topics: List[str], count: int, references: List[Dict]) -> str:
        """Build prompt for structured questions with sub-questions."""
        
        # Format reference examples
        ref_text = ""
        if references:
            ref_text = "\n=== ‡∂Ü‡∂Ø‡∂ª‡∑ä‡∑Å ‡∑Ä‡∑ä‚Äç‡∂∫‡∑î‡∑Ñ‡∂ú‡∂≠ ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂± ===\n"
            for i, ref in enumerate(references[:2], 1):
                ref_text += f"\n‡∂ã‡∂Ø‡∑è‡∑Ñ‡∂ª‡∂´ {i}:\n"
                ref_text += f"‡∂¥‡∑ä‚Äç‡∂ª‡∂∞‡∑è‡∂± ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∂∫: {ref.get('question', '')[:200]}...\n"
                
                sub_qs = ref.get('sub_questions', [])
                if sub_qs:
                    ref_text += "‡∂ã‡∂¥ ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±:\n"
                    for j, sq in enumerate(sub_qs[:3]):
                        sq_text = sq.get('sub_question', '')[:100]
                        ref_text += f"  ({chr(ord('‡∂Ö') + j)}) {sq_text}...\n"
        
        topics_str = ", ".join(topics)
        
        prompt = f"""‡∂î‡∂∂ O/L ‡∂ú‡∂´‡∑í‡∂≠‡∂∫ ‡∑Ä‡∑í‡∂∑‡∑è‡∂ú ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂± ‡∑É‡∑è‡∂Ø‡∂± ‡∑Ä‡∑í‡∑Å‡∑ö‡∑Ç‡∂• ‡∂ú‡∑î‡∂ª‡∑î‡∑Ä‡∂ª‡∂∫‡∑ô‡∂ö‡∑ä.

‡∂ö‡∑è‡∂ª‡∑ä‡∂∫‡∂∫: ‡∑Ä‡∑ä‚Äç‡∂∫‡∑î‡∑Ñ‡∂ú‡∂≠ (Structured) ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂± {count}‡∂ö‡∑ä ‡∑É‡∑è‡∂Ø‡∂±‡∑ä‡∂±
‡∂∏‡∑è‡∂≠‡∑ò‡∂ö‡∑è: {topics_str}

{ref_text}

=== ‡∑Ä‡∑ä‚Äç‡∂∫‡∑î‡∑Ñ‡∂ú‡∂≠ ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∂∫‡∂ö ‡∂Ω‡∂ö‡∑ä‡∑Ç‡∂´ ===
1. ‡∂¥‡∑ä‚Äç‡∂ª‡∂∞‡∑è‡∂± ‡∑É‡∂±‡∑ä‡∂Ø‡∂ª‡∑ä‡∂∑‡∂∫‡∂ö‡∑ä ‡∑Ñ‡∑ù ‡∂≠‡∂≠‡∑ä‡∂≠‡∑ä‡∑Ä‡∂∫‡∂ö‡∑ä ‡∑Ä‡∑í‡∑É‡∑ä‡∂≠‡∂ª ‡∂ö‡∂ª‡∂∫‡∑í
2. ‡∂ã‡∂¥ ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂± 3-5‡∂ö‡∑ä ‡∂Ö‡∂©‡∂Ç‡∂ú‡∑î ‡∑Ä‡∑ö (‡∂Ö, ‡∂Ü, ‡∂á, ‡∂à, ‡∂â)
3. ‡∂ã‡∂¥ ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂± ‡∂ë‡∂ö‡∑í‡∂±‡∑ô‡∂ö‡∂ß ‡∑É‡∂∏‡∑ä‡∂∂‡∂±‡∑ä‡∂∞ ‡∑Ä‡∑ö
4. ‡∑É‡∑ë‡∂∏ ‡∂ã‡∂¥ ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∂∫‡∂ö‡∂∏ ‡∂¥‡∑í‡∑Ö‡∑í‡∂≠‡∑î‡∂ª‡∑î ‡∂¥‡∑í‡∂∫‡∑Ä‡∂ª 1-3‡∂ö‡∑ä ‡∂á‡∂≠

=== ‡∂±‡∑í‡∂∏‡∑ê‡∑Ä‡∑î‡∂∏‡∑ä ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í‡∂∫ ===

STRUCTURED_START
NUMBER: [‡∂Ö‡∂Ç‡∂ö‡∂∫]
TOPIC: [‡∂∏‡∑è‡∂≠‡∑ò‡∂ö‡∑è‡∑Ä]
MAIN_CONTEXT: [‡∂¥‡∑ä‚Äç‡∂ª‡∂∞‡∑è‡∂± ‡∑É‡∂±‡∑ä‡∂Ø‡∂ª‡∑ä‡∂∑‡∂∫ - ‡∑É‡∑í‡∂Ø‡∑ä‡∂∞‡∑í‡∂∫ ‡∑Ä‡∑í‡∑É‡∑ä‡∂≠‡∂ª ‡∂ö‡∂ª‡∂±‡∑ä‡∂±, ‡∂ã‡∂Ø‡∑è: "‡∂ª‡∑Ä‡∑ì ‡∂ª‡∑î‡∂¥‡∑í‡∂∫‡∂Ω‡∑ä 80000‡∂ö‡∑ä ‡∂∂‡∑ê‡∂Ç‡∂ö‡∑î‡∑Ä‡∂ö 12% ‡∑Ä‡∑è‡∂ª‡∑ä‡∑Ç‡∑í‡∂ö ‡∂¥‡∑ú‡∂Ω‡∑ì ‡∂Ö‡∂±‡∑î‡∂¥‡∑è‡∂≠‡∂∫‡∂ö‡∂ß ‡∂≠‡∑ê‡∂±‡∑ä‡∂¥‡∂≠‡∑ä ‡∂ö‡∂ª‡∂∫‡∑í."]

SUB_QUESTION: (‡∂Ö)
TEXT: [‡∂¥‡∑Ö‡∂∏‡∑î ‡∂ã‡∂¥ ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∂∫ - ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∂∫‡∂ö‡∑ä ‡∂Ω‡∑ô‡∑É ‡∂Ω‡∑í‡∂∫‡∂±‡∑ä‡∂±, ‡∂ã‡∂Ø‡∑è: "‡∂¥‡∑Ö‡∂∏‡∑î ‡∑Ä‡∑É‡∂ª ‡∂Ö‡∑Ä‡∑É‡∑è‡∂±‡∂∫‡∑ö ‡∂Ω‡∑ê‡∂∂‡∑ô‡∂± ‡∂¥‡∑ú‡∂Ω‡∑í‡∂∫ ‡∂ö‡∑ì‡∂∫‡∂Ø?"]
STEPS:
- [‡∂¥‡∑í‡∂∫‡∑Ä‡∂ª ‡∑Ä‡∑í‡∑É‡∑ä‡∂≠‡∂ª‡∂∫] = [‡∂ú‡∂´‡∂±‡∂∫/‡∂¥‡∑í‡∑Ö‡∑í‡∂≠‡∑î‡∂ª]
- [‡∂¥‡∑í‡∂∫‡∑Ä‡∂ª ‡∑Ä‡∑í‡∑É‡∑ä‡∂≠‡∂ª‡∂∫] = [‡∂ú‡∂´‡∂±‡∂∫/‡∂¥‡∑í‡∑Ö‡∑í‡∂≠‡∑î‡∂ª]
ANSWER: [‡∂∏‡∑ô‡∂∏ ‡∂ã‡∂¥ ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∂∫‡∑ö ‡∂¥‡∑í‡∑Ö‡∑í‡∂≠‡∑î‡∂ª]

SUB_QUESTION: (‡∂Ü)
TEXT: [‡∂Ø‡∑ô‡∑Ä‡∂± ‡∂ã‡∂¥ ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∂∫]
STEPS:
- [‡∂¥‡∑í‡∂∫‡∑Ä‡∂ª] = [‡∂¥‡∑í‡∑Ö‡∑í‡∂≠‡∑î‡∂ª]
ANSWER: [‡∂¥‡∑í‡∑Ö‡∑í‡∂≠‡∑î‡∂ª]

SUB_QUESTION: (‡∂á)
TEXT: [‡∂≠‡∑ô‡∑Ä‡∂± ‡∂ã‡∂¥ ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∂∫]
STEPS:
- [‡∂¥‡∑í‡∂∫‡∑Ä‡∂ª] = [‡∂¥‡∑í‡∑Ö‡∑í‡∂≠‡∑î‡∂ª]
ANSWER: [‡∂¥‡∑í‡∑Ö‡∑í‡∂≠‡∑î‡∂ª]

SUB_QUESTION: (‡∂à)
TEXT: [‡∑É‡∑í‡∑Ä‡∑ä‡∑Ä‡∂± ‡∂ã‡∂¥ ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∂∫]
STEPS:
- [‡∂¥‡∑í‡∂∫‡∑Ä‡∂ª] = [‡∂¥‡∑í‡∑Ö‡∑í‡∂≠‡∑î‡∂ª]
ANSWER: [‡∂¥‡∑í‡∑Ö‡∑í‡∂≠‡∑î‡∂ª]

STRUCTURED_END

---

=== ‡∑Ä‡∑ê‡∂Ø‡∂ú‡∂≠‡∑ä ‡∂±‡∑ì‡∂≠‡∑í ===
1. MAIN_CONTEXT ‡∂∫‡∂±‡∑î ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∂∫‡∂ö‡∑ä ‡∂±‡∑ú‡∑Ä‡∑ö - ‡∂ë‡∂∫ ‡∑É‡∑í‡∂Ø‡∑ä‡∂∞‡∑í‡∂∫‡∂ö‡∑ä ‡∑Ñ‡∑ù ‡∂≠‡∂≠‡∑ä‡∂≠‡∑ä‡∑Ä‡∂∫‡∂ö‡∑ä ‡∑Ä‡∑í‡∑É‡∑ä‡∂≠‡∂ª ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏‡∂ö‡∑í
2. ‡∑É‡∑ë‡∂∏ SUB_QUESTION ‡∂ë‡∂ö‡∂ö‡∑ä‡∂∏ ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∂∫‡∂ö‡∑ä ‡∑Ä‡∑í‡∂∫ ‡∂∫‡∑î‡∂≠‡∑î‡∂∫ (? ‡∑É‡∂Ω‡∂ö‡∑î‡∂´ ‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è ‡∂ö‡∂ª‡∂±‡∑ä‡∂±)
3. ‡∂ã‡∂¥ ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂± ‡∂Ö‡∑Ä‡∂∏ ‡∑Ä‡∑Å‡∂∫‡∑ô‡∂±‡∑ä 3‡∂ö‡∑ä ‡∑É‡∑Ñ ‡∂ã‡∂¥‡∂ª‡∑í‡∂∏ 5‡∂ö‡∑ä ‡∂≠‡∑í‡∂∂‡∑í‡∂∫ ‡∂∫‡∑î‡∂≠‡∑î‡∂∫
4. ‡∑É‡∑ë‡∂∏ ‡∂ã‡∂¥ ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∂∫‡∂ö‡∂ß‡∂∏ STEPS ‡∑É‡∑Ñ ANSWER ‡∂≠‡∑í‡∂∂‡∑í‡∂∫ ‡∂∫‡∑î‡∂≠‡∑î‡∂∫
5. ‡∂ã‡∂¥ ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂± ‡∂ë‡∂ö‡∑í‡∂±‡∑ô‡∂ö‡∂ß ‡∑É‡∂∏‡∑ä‡∂∂‡∂±‡∑ä‡∂∞ ‡∑Ä‡∑í‡∂∫ ‡∂∫‡∑î‡∂≠‡∑î‡∂∫ (‡∂¥‡∑ô‡∂ª ‡∂¥‡∑í‡∑Ö‡∑í‡∂≠‡∑î‡∂ª‡∑î ‡∂¥‡∑É‡∑î ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∑Ä‡∂Ω‡∂ß ‡∂Ö‡∑Ä‡∑Å‡∑ä‚Äç‡∂∫ ‡∑Ä‡∑í‡∂∫ ‡∑Ñ‡∑ê‡∂ö)

=== ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂± ‡∑É‡∂±‡∑ä‡∂Ø‡∂ª‡∑ä‡∂∑ ‡∂ã‡∂Ø‡∑è‡∑Ñ‡∂ª‡∂´ ===
- ‡∂¥‡∑ú‡∂Ω‡∑í‡∂∫: "‡∑É‡∑î‡∂∏‡∂± ‡∂ª‡∑î‡∂¥‡∑í‡∂∫‡∂Ω‡∑ä 50000‡∂ö‡∑ä ‡∂∂‡∑ê‡∂Ç‡∂ö‡∑î‡∑Ä‡∂ö 10% ‡∑Ä‡∑è‡∂ª‡∑ä‡∑Ç‡∑í‡∂ö ‡∂¥‡∑ú‡∂Ω‡∑ì ‡∂Ö‡∂±‡∑î‡∂¥‡∑è‡∂≠‡∂∫‡∂ö‡∂ß ‡∂≠‡∑ê‡∂±‡∑ä‡∂¥‡∂≠‡∑ä ‡∂ö‡∂ª‡∂∫‡∑í..."
- ‡∂ö‡∑ú‡∂ß‡∑É‡∑ä: "‡∑É‡∂∏‡∑è‡∂ú‡∂∏‡∂ö ‡∂ö‡∑ú‡∂ß‡∑É‡∑ä 10000‡∂ö‡∑ä ‡∂±‡∑í‡∂ö‡∑î‡∂≠‡∑ä ‡∂ö‡∂ª ‡∂á‡∂≠. ‡∂ö‡∑ú‡∂ß‡∑É‡∂ö ‡∂∏‡∑í‡∂Ω ‡∂ª‡∑î‡∂¥‡∑í‡∂∫‡∂Ω‡∑ä 25 ‡∂ö‡∑í..."
- ‡∂∂‡∂Ø‡∑î: "‡∂¢‡∂∫‡∂±‡∑ä‡∂≠ ‡∂∏‡∑É‡∂ö‡∂ß ‡∂ª‡∑î‡∂¥‡∑í‡∂∫‡∂Ω‡∑ä 120000‡∂ö ‡∑Ä‡∑ê‡∂ß‡∑î‡∂¥‡∂ö‡∑ä ‡∂Ω‡∂∂‡∂∫‡∑í. ‡∂Ü‡∂Ø‡∑è‡∂∫‡∂∏‡∑ä ‡∂∂‡∂Ø‡∑î ‡∂Ö‡∂±‡∑î‡∂¥‡∑è‡∂≠‡∂∫ 6% ‡∂ö‡∑í..."

‡∂Ø‡∑ê‡∂±‡∑ä ‡∑Ä‡∑ä‚Äç‡∂∫‡∑î‡∑Ñ‡∂ú‡∂≠ ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂± {count}‡∂ö‡∑ä ‡∑É‡∑è‡∂Ø‡∂±‡∑ä‡∂±:
"""
        return prompt
    
    def _parse_structured_response(self, text: str) -> List[Dict]:
        """Parse structured questions from response."""
        questions = []
        
        # Split by STRUCTURED_START...STRUCTURED_END
        pattern = r'STRUCTURED_START(.*?)STRUCTURED_END'
        matches = re.findall(pattern, text, re.DOTALL)
        
        if not matches:
            # Try splitting by ---
            parts = text.split('---')
            for part in parts:
                if 'MAIN_CONTEXT:' in part or 'SUB_QUESTION:' in part:
                    matches.append(part)
        
        for match in matches:
            try:
                q_data = {}
                
                # Extract number
                num_match = re.search(r'NUMBER:\s*(\d+)', match)
                q_data['question_number'] = int(num_match.group(1)) if num_match else len(questions) + 1
                
                # Extract topic
                topic_match = re.search(r'TOPIC:\s*(.+?)(?:\n|$)', match)
                q_data['topics'] = [topic_match.group(1).strip()] if topic_match else []
                
                # Extract main context
                context_match = re.search(r'MAIN_CONTEXT:\s*(.+?)(?=\nSUB_QUESTION:|$)', match, re.DOTALL)
                q_data['question'] = context_match.group(1).strip() if context_match else ""
                
                # Extract sub-questions
                sub_questions = []
                sub_pattern = r'SUB_QUESTION:\s*\(([‡∂Ö-‡∂âa-e\d]+)\)\s*\nTEXT:\s*(.+?)(?=\nSTEPS:|$)(.*?)(?=\nSUB_QUESTION:|STRUCTURED_END|$)'
                sub_matches = re.findall(sub_pattern, match, re.DOTALL)
                
                # If pattern doesn't match, try alternative
                if not sub_matches:
                    sub_pattern2 = r'SUB_QUESTION:\s*\(([^)]+)\)[^\n]*\n(?:TEXT:\s*)?(.+?)(?:\n\s*STEPS:|ANSWER:)(.*?)(?=SUB_QUESTION:|STRUCTURED_END|---|\Z)'
                    sub_matches = re.findall(sub_pattern2, match, re.DOTALL)
                
                for label, sub_text, rest in sub_matches:
                    sub_q = {
                        "sub_question_label": f"({label.strip()})",
                        "sub_question": sub_text.strip(),
                        "answer_steps": []
                    }
                    
                    # Extract steps
                    steps_match = re.search(r'STEPS:(.*?)(?=ANSWER:|SUB_QUESTION:|$)', rest, re.DOTALL)
                    if steps_match:
                        step_lines = steps_match.group(1).strip().split('\n')
                        for line in step_lines:
                            line = line.strip().lstrip('-').strip()
                            if '=' in line:
                                parts = line.split('=', 1)
                                sub_q['answer_steps'].append({
                                    "description": parts[0].strip(),
                                    "value": parts[1].strip()
                                })
                    
                    # Extract answer
                    ans_match = re.search(r'ANSWER:\s*(.+?)(?:\n|$)', rest)
                    if ans_match:
                        sub_q['answer'] = ans_match.group(1).strip()
                    
                    if sub_q['sub_question']:
                        sub_questions.append(sub_q)
                
                q_data['sub_questions'] = sub_questions
                
                # Only add if we have main question and at least 2 sub-questions
                if q_data['question'] and len(sub_questions) >= 2:
                    questions.append(q_data)
                else:
                    print(f"  ‚ö†Ô∏è Skipped: main_q={bool(q_data['question'])}, sub_qs={len(sub_questions)}")
                    
            except Exception as e:
                print(f"  ‚ö†Ô∏è Parse error: {e}")
                continue
        
        return questions
    
    def generate_structured_questions(
        self,
        count: int = 3,
        topics: Optional[List[str]] = None,
        api_delay: float = 4.0
    ) -> Dict:
        """
        Generate structured questions with sub-questions.
        
        Args:
            count: Number of questions to generate (1-5)
            topics: Optional list of topics to use
            api_delay: Delay between API calls
        
        Returns:
            Dict with questions and metadata
        """
        print(f"\n{'='*60}")
        print(f"üìã GENERATING {count} STRUCTURED QUESTIONS")
        print(f"{'='*60}")
        
        if not self.past_papers_loaded:
            raise ValueError("Past papers not loaded. Call load_past_paper_questions() first.")
        
        self._ensure_model()
        start_time = time.time()
        
        # Select topics if not provided
        if not topics:
            topics = self._select_topics(count)
        
        print(f"üìö Topics: {topics}")
        
        # Get reference questions
        references = self._get_reference_questions(topics, 'structured', count=2)
        
        all_questions = []
        attempts = 0
        max_attempts = 4
        
        # Generate one at a time for better quality
        while len(all_questions) < count and attempts < max_attempts:
            attempts += 1
            remaining = count - len(all_questions)
            
            print(f"\n  Attempt {attempts}: Generating {min(2, remaining)} structured questions...")
            
            self._rate_limit_wait()
            
            try:
                prompt = self._build_structured_prompt(topics, min(2, remaining), references)
                
                response = self.model.generate_content(
                    prompt,
                    generation_config=self.generation_config,
                    safety_settings=self.safety_settings
                )
                
                if response.text:
                    new_questions = self._parse_structured_response(response.text)
                    
                    for q in new_questions:
                        if len(all_questions) < count:
                            q['question_number'] = len(all_questions) + 1
                            all_questions.append(q)
                    
                    print(f"  ‚úÖ Parsed {len(new_questions)} questions. Total: {len(all_questions)}/{count}")
                
                time.sleep(api_delay)
                
            except Exception as e:
                print(f"  ‚ùå Error: {str(e)[:100]}")
                time.sleep(api_delay)
        
        generation_time = round(time.time() - start_time, 2)
        
        return {
            "type": "structured",
            "questions": all_questions,
            "count": len(all_questions),
            "requested": count,
            "topics_used": list(set(topics)),
            "generation_time_seconds": generation_time
        }
    
    # ==================== ESSAY TYPE GENERATION ====================
    
    def _build_essay_prompt(self, topics: List[str], count: int, references: List[Dict]) -> str:
        """Build prompt for essay type questions with real-life scenarios."""
        
        # Format reference examples
        ref_text = ""
        if references:
            ref_text = "\n=== ‡∂Ü‡∂Ø‡∂ª‡∑ä‡∑Å ‡∂ª‡∂†‡∂±‡∑è ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂± ===\n"
            for i, ref in enumerate(references[:2], 1):
                ref_text += f"\n‡∂ã‡∂Ø‡∑è‡∑Ñ‡∂ª‡∂´ {i}:\n"
                ref_text += f"‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∂∫: {ref.get('question', '')[:300]}...\n"
        
        topics_str = ", ".join(topics)
        
        prompt = f"""‡∂î‡∂∂ O/L ‡∂ú‡∂´‡∑í‡∂≠‡∂∫ ‡∑Ä‡∑í‡∂∑‡∑è‡∂ú ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂± ‡∑É‡∑è‡∂Ø‡∂± ‡∑Ä‡∑í‡∑Å‡∑ö‡∑Ç‡∂• ‡∂ú‡∑î‡∂ª‡∑î‡∑Ä‡∂ª‡∂∫‡∑ô‡∂ö‡∑ä.

‡∂ö‡∑è‡∂ª‡∑ä‡∂∫‡∂∫: ‡∂ª‡∂†‡∂±‡∑è ‡∑Ä‡∂ª‡∑ä‡∂ú‡∂∫‡∑ö (Essay Type) ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂± {count}‡∂ö‡∑ä ‡∑É‡∑è‡∂Ø‡∂±‡∑ä‡∂±
‡∂∏‡∑è‡∂≠‡∑ò‡∂ö‡∑è: {topics_str}

{ref_text}

=== ‡∂ª‡∂†‡∂±‡∑è ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∂∫‡∂ö ‡∂Ω‡∂ö‡∑ä‡∑Ç‡∂´ ===
1. ‡∑É‡∑ê‡∂∂‡∑ë ‡∂¢‡∑ì‡∑Ä‡∑í‡∂≠ ‡∂≠‡∂≠‡∑ä‡∂≠‡∑ä‡∑Ä‡∂∫‡∂ö‡∑ä ‡∑Ä‡∑í‡∑É‡∑ä‡∂≠‡∂ª‡∑è‡∂≠‡∑ä‡∂∏‡∂ö‡∑Ä ‡∂â‡∂Ø‡∑í‡∂ª‡∑í‡∂¥‡∂≠‡∑ä ‡∂ö‡∂ª‡∂∫‡∑í
2. ‡∑Ä‡∑í‡∑É‡∑ä‡∂≠‡∂ª‡∂∫ ‡∂Ø‡∑í‡∂ú ‡∑Ä‡∑í‡∂∫ ‡∂∫‡∑î‡∂≠‡∑î‡∂∫ (‡∑Ä‡∑è‡∂ö‡∑ä‚Äç‡∂∫ 3-5)
3. ‡∂ã‡∂¥ ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂± 4-6‡∂ö‡∑ä ‡∂Ö‡∂©‡∂Ç‡∂ú‡∑î ‡∑Ä‡∑ö - (i), (ii), (iii), (iv), (v)
4. ‡∂ã‡∂¥ ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂± ‡∂ë‡∂ö‡∑í‡∂±‡∑ô‡∂ö‡∂ß ‡∑É‡∂∏‡∑ä‡∂∂‡∂±‡∑ä‡∂∞ ‡∑É‡∑Ñ ‡∂¥‡∑ä‚Äç‡∂ª‡∂ú‡∂≠‡∑í‡∑Å‡∑ì‡∂Ω‡∑ì
5. ‡∂Ö‡∑Ä‡∑É‡∑è‡∂± ‡∂ã‡∂¥ ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∂∫ ‡∑É‡∑è‡∂∏‡∑è‡∂±‡∑ä‚Äç‡∂∫‡∂∫‡∑ô‡∂±‡∑ä ‡∑É‡∑è‡∂ª‡∑è‡∂Ç‡∑Å‡∂∫‡∂ö‡∑ä ‡∑Ñ‡∑ù ‡∑É‡∂Ç‡∑É‡∂±‡∑ä‡∂Ø‡∂±‡∂∫‡∂ö‡∑ä

=== ‡∑É‡∑ê‡∂∂‡∑ë ‡∂¢‡∑ì‡∑Ä‡∑í‡∂≠ ‡∑É‡∑í‡∂Ø‡∑ä‡∂∞‡∑í ‡∂ã‡∂Ø‡∑è‡∑Ñ‡∂ª‡∂´ ===
- "‡∂ö‡∂∏‡∂Ω‡∑ä ‡∂≠‡∂∏ ‡∂±‡∑í‡∑Ä‡∑É ‡∂∏‡∑É‡∂ö‡∂ß ‡∂ª‡∑î‡∂¥‡∑í‡∂∫‡∂Ω‡∑ä 8000 ‡∂∂‡∑ê‡∂ú‡∑í‡∂±‡∑ä ‡∑Ä‡∂ª‡∑ä‡∑Ç‡∂∫‡∂ö‡∂ß ‡∂∂‡∂Ø‡∑î ‡∂Ø‡∑ì ‡∂ë‡∂∏ ‡∂∏‡∑î‡∂Ø‡∂Ω‡∑ä ‡∂ë‡∂ö‡∑Ä‡∂ª ‡∂Ω‡∂∂‡∑è‡∂ú‡∂±‡∑í‡∂∫‡∑í..."
- "‡∂ë‡∂ö‡∂ö‡∑ä ‡∂ª‡∑î‡∂¥‡∑í‡∂∫‡∂Ω‡∑ä 84000 ‡∂∂‡∑ê‡∂ú‡∑í‡∂±‡∑ä ‡∑Ä‡∂ß‡∑í‡∂±‡∑è ‡∂ª‡∑ñ‡∂¥‡∑Ä‡∑è‡∑Ñ‡∑í‡∂±‡∑ì ‡∂≠‡∑ú‡∂ú‡∂∫‡∂ö‡∑ä ‡∑Ä‡∑í‡∂ö‡∑í‡∂´‡∑ì‡∂∏‡∂ß ‡∂≠‡∑í‡∂∂‡∑ö. ‡∂ª‡∑î‡∑Ä‡∑í‡∂±‡∑í..."
- "‡∂Ö‡∂∏‡∂Ω‡∑è ‡∑É‡∑Ñ ‡∑É‡∑î‡∂∏‡∂±‡∑è ‡∂±‡∑í‡∑Ä‡∑è‡∂©‡∑î ‡∂ö‡∑è‡∂Ω‡∂∫ ‡∂≠‡∑î‡∑Ö‡∂Ø‡∑ì ‡∂ë‡∂ö‡∑ä‡∂≠‡∂ª‡∑è ‡∂±‡∑Ä‡∂ö‡∂≠‡∑è‡∑Ä‡∂ö‡∑ä ‡∂ö‡∑í‡∂∫‡∑Ä‡∑ì‡∂∏‡∂ß ‡∂≠‡∑ì‡∂ª‡∂´‡∂∫ ‡∂ö‡∂ª‡∂≠‡∑í..."
- "‡∑É‡∑è‡∂Ø‡∂∫‡∂ö‡∂ß ‡∑É‡∑Ñ‡∂∑‡∑è‡∂ú‡∑í ‡∑Ä‡∑ñ ‡∑Ä‡∑ê‡∂©‡∑í‡∑Ñ‡∑í‡∂ß‡∑í‡∂∫‡∂±‡∑ä‡∂ß‡∂≠‡∑ä ‡∑Ö‡∂∏‡∂∫‡∑í‡∂±‡∑ä‡∂ß‡∂≠‡∑ä ‡∂ª‡∑É‡∂ö‡∑ê‡∑Ä‡∑í‡∂Ω‡∑í‡∑Ä‡∂Ω‡∑í‡∂±‡∑ä ‡∑É‡∂Ç‡∂ú‡∑ä‚Äç‡∂ª‡∑Ñ ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏ ‡∑É‡∂≥‡∑Ñ‡∑è..."

=== ‡∂±‡∑í‡∂∏‡∑ê‡∑Ä‡∑î‡∂∏‡∑ä ‡∂Ü‡∂ö‡∑ò‡∂≠‡∑í‡∂∫ ===

ESSAY_START
NUMBER: [‡∂Ö‡∂Ç‡∂ö‡∂∫]
TOPICS: [‡∂∏‡∑è‡∂≠‡∑ò‡∂ö‡∑è ‡∂ö‡∑ú‡∂∏‡∑è‡∑Ä‡∑ô‡∂±‡∑ä ‡∑Ä‡∑ô‡∂±‡∑ä ‡∂ö‡∂ª]
SCENARIO: [‡∑É‡∑ê‡∂∂‡∑ë ‡∂¢‡∑ì‡∑Ä‡∑í‡∂≠ ‡∑É‡∑í‡∂Ø‡∑ä‡∂∞‡∑í‡∂∫ ‡∑Ä‡∑í‡∑É‡∑ä‡∂≠‡∂ª‡∑è‡∂≠‡∑ä‡∂∏‡∂ö‡∑Ä - ‡∂Ö‡∑Ä‡∂∏ ‡∑Ä‡∑Å‡∂∫‡∑ô‡∂±‡∑ä ‡∑Ä‡∑è‡∂ö‡∑ä‚Äç‡∂∫ 3‡∂ö‡∑ä. ‡∂¥‡∑î‡∂Ø‡∑ä‡∂ú‡∂Ω‡∂∫‡∂±‡∑ä‡∂ú‡∑ö ‡∂±‡∂∏‡∑ä, ‡∂∏‡∑î‡∂Ø‡∂Ω‡∑ä ‡∂¥‡∑ä‚Äç‡∂ª‡∂∏‡∑è‡∂´, ‡∂¥‡∑ä‚Äç‡∂ª‡∂≠‡∑í‡∑Å‡∂≠, ‡∂ö‡∑è‡∂Ω ‡∑É‡∑ì‡∂∏‡∑è ‡∂Ü‡∂Ø‡∑í‡∂∫ ‡∂á‡∂≠‡∑î‡∑Ö‡∂≠‡∑ä ‡∂ö‡∂ª‡∂±‡∑ä‡∂±.]

SUB_QUESTION: (i)
TEXT: [‡∂¥‡∑Ö‡∂∏‡∑î ‡∂ã‡∂¥ ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∂∫ - ? ‡∑É‡∂Ω‡∂ö‡∑î‡∂´ ‡∑É‡∂∏‡∂ü]
STEPS:
- [‡∂¥‡∑í‡∂∫‡∑Ä‡∂ª] = [‡∂ú‡∂´‡∂±‡∂∫]
- [‡∂¥‡∑í‡∂∫‡∑Ä‡∂ª] = [‡∂¥‡∑í‡∑Ö‡∑í‡∂≠‡∑î‡∂ª]
ANSWER: [‡∂¥‡∑í‡∑Ö‡∑í‡∂≠‡∑î‡∂ª]

SUB_QUESTION: (ii)
TEXT: [‡∂Ø‡∑ô‡∑Ä‡∂± ‡∂ã‡∂¥ ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∂∫]
STEPS:
- [‡∂¥‡∑í‡∂∫‡∑Ä‡∂ª] = [‡∂ú‡∂´‡∂±‡∂∫]
ANSWER: [‡∂¥‡∑í‡∑Ö‡∑í‡∂≠‡∑î‡∂ª]

SUB_QUESTION: (iii)
TEXT: [‡∂≠‡∑ô‡∑Ä‡∂± ‡∂ã‡∂¥ ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∂∫]
STEPS:
- [‡∂¥‡∑í‡∂∫‡∑Ä‡∂ª] = [‡∂ú‡∂´‡∂±‡∂∫]
ANSWER: [‡∂¥‡∑í‡∑Ö‡∑í‡∂≠‡∑î‡∂ª]

SUB_QUESTION: (iv)
TEXT: [‡∑É‡∑í‡∑Ä‡∑ä‡∑Ä‡∂± ‡∂ã‡∂¥ ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∂∫]
STEPS:
- [‡∂¥‡∑í‡∂∫‡∑Ä‡∂ª] = [‡∂ú‡∂´‡∂±‡∂∫]
ANSWER: [‡∂¥‡∑í‡∑Ö‡∑í‡∂≠‡∑î‡∂ª]

SUB_QUESTION: (v)
TEXT: [‡∂¥‡∑É‡∑ä‡∑Ä‡∂± ‡∂ã‡∂¥ ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∂∫ - ‡∑É‡∂Ç‡∑É‡∂±‡∑ä‡∂Ø‡∂±‡∂∫‡∂ö‡∑ä ‡∑Ñ‡∑ù ‡∂±‡∑í‡∂ú‡∂∏‡∂±‡∂∫‡∂ö‡∑ä]
STEPS:
- [‡∂¥‡∑í‡∂∫‡∑Ä‡∂ª] = [‡∂ú‡∂´‡∂±‡∂∫]
ANSWER: [‡∂¥‡∑í‡∑Ö‡∑í‡∂≠‡∑î‡∂ª]

ESSAY_END

---

=== ‡∑Ä‡∑ê‡∂Ø‡∂ú‡∂≠‡∑ä ‡∂±‡∑ì‡∂≠‡∑í ===
1. SCENARIO ‡∂∫‡∂±‡∑î ‡∑É‡∑ê‡∂∂‡∑ë ‡∂¢‡∑ì‡∑Ä‡∑í‡∂≠ ‡∑É‡∑í‡∂Ø‡∑ä‡∂∞‡∑í‡∂∫‡∂ö‡∑ä - ‡∑Ä‡∑í‡∑É‡∑ä‡∂≠‡∂ª‡∑è‡∂≠‡∑ä‡∂∏‡∂ö ‡∑Ä‡∑í‡∂∫ ‡∂∫‡∑î‡∂≠‡∑î‡∂∫
2. ‡∂¥‡∑î‡∂Ø‡∑ä‡∂ú‡∂Ω‡∂∫‡∂±‡∑ä‡∂ú‡∑ö ‡∑É‡∑í‡∂Ç‡∑Ñ‡∂Ω ‡∂±‡∂∏‡∑ä ‡∂∑‡∑è‡∑Ä‡∑í‡∂≠‡∑è ‡∂ö‡∂ª‡∂±‡∑ä‡∂± (‡∑É‡∑î‡∂∏‡∂±, ‡∂ö‡∂∏‡∂Ω‡∑ä, ‡∂±‡∑í‡∂∏‡∑è‡∂Ω‡∑í, ‡∂ª‡∑Ä‡∑ì, ‡∂Ü‡∂Ø‡∑í‡∂∫)
3. ‡∑É‡∑ë‡∂∏ SUB_QUESTION ‡∂ë‡∂ö‡∂ö‡∑ä‡∂∏ ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∂∫‡∂ö‡∑ä ‡∑Ä‡∑í‡∂∫ ‡∂∫‡∑î‡∂≠‡∑î‡∂∫ (? ‡∑É‡∂Ω‡∂ö‡∑î‡∂´)
4. ‡∂ã‡∂¥ ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂± ‡∂Ö‡∑Ä‡∂∏ 4‡∂ö‡∑ä ‡∑É‡∑Ñ ‡∂ã‡∂¥‡∂ª‡∑í‡∂∏ 6‡∂ö‡∑ä
5. ‡∂ã‡∂¥ ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂± ‡∂¥‡∑ô‡∂ª ‡∂¥‡∑í‡∑Ö‡∑í‡∂≠‡∑î‡∂ª‡∑î ‡∂∏‡∂≠ ‡∂ª‡∂≥‡∑è ‡∂¥‡∑Ä‡∂≠‡∑í‡∂∫ ‡∑Ñ‡∑ê‡∂ö
6. ‡∂Ö‡∑Ä‡∑É‡∑è‡∂± ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∂∫ ‡∑É‡∑è‡∂∏‡∑è‡∂±‡∑ä‚Äç‡∂∫‡∂∫‡∑ô‡∂±‡∑ä "‡∂¥‡∑ô‡∂±‡∑ä‡∑Ä‡∂±‡∑ä‡∂±", "‡∑É‡∂Ç‡∑É‡∂±‡∑ä‡∂Ø‡∂±‡∂∫ ‡∂ö‡∂ª‡∂±‡∑ä‡∂±", "‡∂≠‡∑ì‡∂ª‡∂´‡∂∫ ‡∂ö‡∂ª‡∂±‡∑ä‡∂±" ‡∑Ä‡∂ª‡∑ä‡∂ú‡∂∫‡∑ö

‡∂Ø‡∑ê‡∂±‡∑ä ‡∂ª‡∂†‡∂±‡∑è ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂± {count}‡∂ö‡∑ä ‡∑É‡∑è‡∂Ø‡∂±‡∑ä‡∂±:
"""
        return prompt
    
    def _parse_essay_response(self, text: str) -> List[Dict]:
        """Parse essay type questions from response."""
        questions = []
        
        # Split by ESSAY_START...ESSAY_END
        pattern = r'ESSAY_START(.*?)ESSAY_END'
        matches = re.findall(pattern, text, re.DOTALL)
        
        if not matches:
            # Try splitting by ---
            parts = text.split('---')
            for part in parts:
                if 'SCENARIO:' in part or 'SUB_QUESTION:' in part:
                    matches.append(part)
        
        for match in matches:
            try:
                q_data = {}
                
                # Extract number
                num_match = re.search(r'NUMBER:\s*(\d+)', match)
                q_data['question_number'] = int(num_match.group(1)) if num_match else len(questions) + 1
                
                # Extract topics
                topics_match = re.search(r'TOPICS?:\s*(.+?)(?:\n|$)', match)
                if topics_match:
                    topics_str = topics_match.group(1).strip()
                    q_data['topics'] = [t.strip() for t in topics_str.split(',')]
                else:
                    q_data['topics'] = []
                
                # Extract scenario
                scenario_match = re.search(r'SCENARIO:\s*(.+?)(?=\nSUB_QUESTION:|$)', match, re.DOTALL)
                q_data['question'] = scenario_match.group(1).strip() if scenario_match else ""
                
                # Extract sub-questions (same pattern as structured)
                sub_questions = []
                sub_pattern = r'SUB_QUESTION:\s*\(([ivxIVX\d]+)\)[^\n]*\n(?:TEXT:\s*)?(.+?)(?:\n\s*STEPS:|ANSWER:)(.*?)(?=SUB_QUESTION:|ESSAY_END|---|\Z)'
                sub_matches = re.findall(sub_pattern, match, re.DOTALL)
                
                for label, sub_text, rest in sub_matches:
                    sub_q = {
                        "sub_question_label": f"({label.strip()})",
                        "sub_question": sub_text.strip(),
                        "answer_steps": []
                    }
                    
                    # Extract steps
                    steps_match = re.search(r'STEPS:(.*?)(?=ANSWER:|SUB_QUESTION:|$)', rest, re.DOTALL)
                    if steps_match:
                        step_lines = steps_match.group(1).strip().split('\n')
                        for line in step_lines:
                            line = line.strip().lstrip('-').strip()
                            if '=' in line:
                                parts = line.split('=', 1)
                                sub_q['answer_steps'].append({
                                    "description": parts[0].strip(),
                                    "value": parts[1].strip()
                                })
                    
                    # Extract answer
                    ans_match = re.search(r'ANSWER:\s*(.+?)(?:\n|$)', rest)
                    if ans_match:
                        sub_q['answer'] = ans_match.group(1).strip()
                    
                    if sub_q['sub_question']:
                        sub_questions.append(sub_q)
                
                q_data['sub_questions'] = sub_questions
                
                # Only add if we have scenario and at least 3 sub-questions
                if q_data['question'] and len(q_data['question']) > 50 and len(sub_questions) >= 3:
                    questions.append(q_data)
                else:
                    print(f"  ‚ö†Ô∏è Skipped: scenario_len={len(q_data.get('question', ''))}, sub_qs={len(sub_questions)}")
                    
            except Exception as e:
                print(f"  ‚ö†Ô∏è Parse error: {e}")
                continue
        
        return questions
    
    def generate_essay_questions(
        self,
        count: int = 5,
        topics: Optional[List[str]] = None,
        api_delay: float = 4.0
    ) -> Dict:
        """
        Generate essay type questions with real-life scenarios.
        
        Args:
            count: Number of questions to generate (1-5)
            topics: Optional list of topics to use
            api_delay: Delay between API calls
        
        Returns:
            Dict with questions and metadata
        """
        print(f"\n{'='*60}")
        print(f"üìù GENERATING {count} ESSAY TYPE QUESTIONS")
        print(f"{'='*60}")
        
        if not self.past_papers_loaded:
            raise ValueError("Past papers not loaded. Call load_past_paper_questions() first.")
        
        self._ensure_model()
        start_time = time.time()
        
        # Select topics if not provided
        if not topics:
            topics = self._select_topics(count * 2)  # More topics for essay
        
        print(f"üìö Topics: {topics}")
        
        # Get reference questions
        references = self._get_reference_questions(topics, 'essay_type', count=2)
        
        all_questions = []
        attempts = 0
        max_attempts = 4
        
        # Generate one at a time for best quality
        while len(all_questions) < count and attempts < max_attempts:
            attempts += 1
            
            print(f"\n  Attempt {attempts}: Generating essay question...")
            
            self._rate_limit_wait()
            
            try:
                prompt = self._build_essay_prompt(topics, 1, references)
                
                response = self.model.generate_content(
                    prompt,
                    generation_config=self.generation_config,
                    safety_settings=self.safety_settings
                )
                
                if response.text:
                    new_questions = self._parse_essay_response(response.text)
                    
                    for q in new_questions:
                        if len(all_questions) < count:
                            q['question_number'] = len(all_questions) + 1
                            all_questions.append(q)
                    
                    print(f"  ‚úÖ Parsed {len(new_questions)} questions. Total: {len(all_questions)}/{count}")
                
                time.sleep(api_delay)
                
            except Exception as e:
                print(f"  ‚ùå Error: {str(e)[:100]}")
                time.sleep(api_delay)
        
        generation_time = round(time.time() - start_time, 2)
        
        return {
            "type": "essay_type",
            "questions": all_questions,
            "count": len(all_questions),
            "requested": count,
            "topics_used": list(set(topics)),
            "generation_time_seconds": generation_time
        }